{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01uOwG8UmMeO"
   },
   "source": [
    "**Word level Multilayer LSTM Model**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m6azsUi6dKWY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "!pip install --upgrade treebank\n",
    "!pip install nltk\n",
    "import treebank\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "#import libraries for model building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GaussianNoise\n",
    "import keras\n",
    "# import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULn5Rz1DmjFT"
   },
   "source": [
    "**Take subset of whole dataset and removing specific stopwords to have more meaningful data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUoX1jO0dKWr",
    "outputId": "878f6402-3509-42b6-a17c-cd9d03df4aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Train_data\n",
    "data = treebank.penn['train']\n",
    "data_train = data[:500000]\n",
    "# stopwords.words('english')\n",
    "stop_words = set()\n",
    "stop_words.add('unk')\n",
    "\n",
    "word_tokens = word_tokenize(data_train)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "# print(word_tokens[10:50])\n",
    "# print(filtered_sentence[10:50])\n",
    "data_f = \" \"\n",
    "data_final = data_f.join(filtered_sentence)\n",
    "print(type(data_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO27HXobm-jN"
   },
   "source": [
    "**Preprocessing Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jB5RmZOUw3I",
    "outputId": "976d8b42-fdf3-419d-c2c9-626a8633a344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449945\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "print(len(treebank.penn['test']))\n",
    "d_Test= treebank.penn['test']\n",
    "d_Test = d_Test[:10000]\n",
    "\n",
    "word_tokens_test = word_tokenize(d_Test)\n",
    "stop_words = set()\n",
    "stop_words.add('unk')\n",
    "filtered_sentence_test = [w for w in word_tokens_test if not w in stop_words]\n",
    " \n",
    "# print(word_tokens_test[10:50])\n",
    "# print(filtered_sentence_test[10:50])\n",
    "\n",
    "data_f_test = \" \"\n",
    "data_final_test = data_f_test.join(filtered_sentence_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qWS7aH7nFV2"
   },
   "source": [
    "**Use Tokenizer to remove punctuations and encode words into a numbers and assign it in a dictionary** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cuT5LfpPdKW5"
   },
   "outputs": [],
   "source": [
    "# Encoding on Train Data\n",
    "tokenizer=Tokenizer(num_words=None,filters='#$%&\"()*+-<=>@[\\\\]^_`{|}~\\t\\n',lower = True, split = ' ')\n",
    "# tokenizer.fit_on_texts([data_final])\n",
    "train_tokens=tokenizer.fit_on_texts([data_final,data_final_test])\n",
    "\n",
    "# convert text into sequences of numbers\n",
    "encoded=tokenizer.texts_to_sequences([data_final])[0]\n",
    "\n",
    "#define total vocabulary size\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "\n",
    "#create seperate lists of 2 sequences since we will use 1 of them as input and one as output\n",
    "sequences=[]\n",
    "num_features = 5\n",
    "for i in range(len(encoded)-(num_features+1)):\n",
    "  sequences.append(encoded[i:i+(num_features+1)])\n",
    "# len(sequences)\n",
    "# sequences[:10]\n",
    "\n",
    "#create dependent and independent variable\n",
    "x=[]\n",
    "y=[]\n",
    "# x = sequences[:,0]\n",
    "# y = sequences[:,1]\n",
    "for i in range(len(sequences)):\n",
    "    row = []\n",
    "    [row.append(sequences[i][j]) for j in range(num_features)]\n",
    "    x.append(row)\n",
    "    y.append(sequences[i][num_features])\n",
    "\n",
    "#convert list to an array\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "y=to_categorical(y,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RFepg_KaWdyK"
   },
   "outputs": [],
   "source": [
    "# Encoding on Test Data\n",
    "encoded_test=tokenizer.texts_to_sequences([data_final_test])[0]\n",
    "\n",
    "#create seperate lists of 2 sequences since we will use 1 of them as input and one as output\n",
    "sequences_test = []\n",
    "num_features = 5\n",
    "for i in range(len(encoded_test)-(num_features+1)):\n",
    "    sequences_test.append(encoded_test[i:i+(num_features+1)])\n",
    "    \n",
    "#create dependent and independent variable\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    " \n",
    "\n",
    "for i in range(len(sequences_test)):\n",
    "    row = []\n",
    "    [row.append(sequences_test[i][j]) for j in range(num_features)]\n",
    "    x_test.append(row)\n",
    "    y_test.append(sequences_test[i][num_features])\n",
    "\n",
    " \n",
    "\n",
    "#convert list to an array\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    " \n",
    "\n",
    "y_test = to_categorical(y_test,vocab_size)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsnDdv7Tnn-D"
   },
   "source": [
    "**Build Model with optimizer = adam, Dropout  = 20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zciDYKTdKXG"
   },
   "outputs": [],
   "source": [
    "#start building model\n",
    "model=Sequential()\n",
    "#add Embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=100,input_length=num_features))\n",
    "#add LSTM layer\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "#output layer\n",
    "model.add(Dense(vocab_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHMjWwtyn_aT"
   },
   "source": [
    "**Compile and fit model to train on dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdZIHD9fdKXI",
    "outputId": "5202f1d0-9431-46b3-e8ec-56fc55fea23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5, 100)            659500    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 64)             42240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6595)              428675    \n",
      "=================================================================\n",
      "Total params: 1,163,439\n",
      "Trainable params: 1,163,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#compile \n",
    "model.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBaozIv0dKXI",
    "outputId": "71efe668-405d-4d47-c56e-72a89477672e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "65494/65494 [==============================] - 838s 13ms/step - loss: 7.3514 - accuracy: 0.0716 - val_loss: 7.7389 - val_accuracy: 0.1090\n",
      "Epoch 2/20\n",
      "65494/65494 [==============================] - 838s 13ms/step - loss: 7.2570 - accuracy: 0.1124 - val_loss: 7.6762 - val_accuracy: 0.1246\n",
      "Epoch 3/20\n",
      "65494/65494 [==============================] - 832s 13ms/step - loss: 6.8494 - accuracy: 0.1335 - val_loss: 7.7472 - val_accuracy: 0.1366\n",
      "Epoch 4/20\n",
      "65494/65494 [==============================] - 831s 13ms/step - loss: 6.4923 - accuracy: 0.1505 - val_loss: 8.0338 - val_accuracy: 0.1353\n",
      "Epoch 5/20\n",
      "65494/65494 [==============================] - 823s 13ms/step - loss: 6.2060 - accuracy: 0.1642 - val_loss: 8.1643 - val_accuracy: 0.1314\n",
      "Epoch 6/20\n",
      "65494/65494 [==============================] - 824s 13ms/step - loss: 5.9608 - accuracy: 0.1737 - val_loss: 8.3076 - val_accuracy: 0.1383\n",
      "Epoch 7/20\n",
      "65494/65494 [==============================] - 822s 13ms/step - loss: 5.6753 - accuracy: 0.1842 - val_loss: 8.4865 - val_accuracy: 0.1303\n",
      "Epoch 8/20\n",
      "65494/65494 [==============================] - 831s 13ms/step - loss: 5.4729 - accuracy: 0.1994 - val_loss: 8.7432 - val_accuracy: 0.1300\n",
      "Epoch 9/20\n",
      "65494/65494 [==============================] - 832s 13ms/step - loss: 5.2880 - accuracy: 0.2102 - val_loss: 8.9470 - val_accuracy: 0.1264\n",
      "Epoch 10/20\n",
      "65494/65494 [==============================] - 854s 13ms/step - loss: 5.0974 - accuracy: 0.2230 - val_loss: 9.0859 - val_accuracy: 0.1234\n",
      "Epoch 11/20\n",
      "65494/65494 [==============================] - 846s 13ms/step - loss: 4.9639 - accuracy: 0.2315 - val_loss: 9.1498 - val_accuracy: 0.1204\n",
      "Epoch 12/20\n",
      "65494/65494 [==============================] - 837s 13ms/step - loss: 4.8197 - accuracy: 0.2432 - val_loss: 9.3549 - val_accuracy: 0.1229\n",
      "Epoch 13/20\n",
      "65494/65494 [==============================] - 823s 13ms/step - loss: 4.6881 - accuracy: 0.2515 - val_loss: 9.3943 - val_accuracy: 0.1198\n",
      "Epoch 14/20\n",
      "65494/65494 [==============================] - 828s 13ms/step - loss: 4.5791 - accuracy: 0.2618 - val_loss: 9.5508 - val_accuracy: 0.1113\n",
      "Epoch 15/20\n",
      "65494/65494 [==============================] - 829s 13ms/step - loss: 4.4654 - accuracy: 0.2740 - val_loss: 9.7555 - val_accuracy: 0.1112\n",
      "Epoch 16/20\n",
      "65494/65494 [==============================] - 838s 13ms/step - loss: 4.3777 - accuracy: 0.2804 - val_loss: 9.8788 - val_accuracy: 0.1113\n",
      "Epoch 17/20\n",
      "65494/65494 [==============================] - 851s 13ms/step - loss: 4.3073 - accuracy: 0.2814 - val_loss: 9.8099 - val_accuracy: 0.1100\n",
      "Epoch 18/20\n",
      "65494/65494 [==============================] - 849s 13ms/step - loss: 4.2364 - accuracy: 0.2927 - val_loss: 10.0532 - val_accuracy: 0.1196\n",
      "Epoch 19/20\n",
      "65494/65494 [==============================] - 853s 13ms/step - loss: 4.1452 - accuracy: 0.2972 - val_loss: 10.0849 - val_accuracy: 0.1125\n",
      "Epoch 20/20\n",
      "65494/65494 [==============================] - 855s 13ms/step - loss: 4.1186 - accuracy: 0.3071 - val_loss: 10.2170 - val_accuracy: 0.1088\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "# history = model.fit(x,y,batch_size=1,epochs=10,validation_data=(x_test,y_test))\n",
    "history = model.fit(x,y,batch_size=1,epochs=20,validation_split =0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MctLGSSaoHAm"
   },
   "source": [
    "**Accuracy based on 1st model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-uz6Eylp9QF",
    "outputId": "e45300b4-adbe-4af3-9d41-91f7b7b5a6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.3252\n",
      "Testing Accuracy:  0.1159\n"
     ]
    }
   ],
   "source": [
    "oss_tr, accuracy_tr = model.evaluate(x, y, verbose=False)\n",
    "print(\"Training Accuracy:  {:.4f}\".format(accuracy_tr)) \n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMloTVuSoSIO"
   },
   "source": [
    "**2nd Model using optimizer = SGD and Regularization with std deviation of 0.075**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iNJ2XznKhOrD"
   },
   "outputs": [],
   "source": [
    "mlstm=Sequential()\n",
    "#add Embedding layer\n",
    "mlstm.add(Embedding(input_dim=vocab_size,output_dim=100,input_length=num_features))\n",
    "#add LSTM layer\n",
    "mlstm.add(LSTM(64,return_sequences=True))\n",
    "mlstm.add(GaussianNoise(0.075))\n",
    "mlstm.add(LSTM(64))\n",
    "mlstm.add(GaussianNoise(0.075))\n",
    "#output layer\n",
    "mlstm.add(Dense(vocab_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "au2zBo_ghOtk",
    "outputId": "d130971a-65e8-4de0-81ea-e35106aff650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 5, 100)            659500    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 5, 64)             42240     \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6595)              428675    \n",
      "=================================================================\n",
      "Total params: 1,163,439\n",
      "Trainable params: 1,163,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlstm.compile(optimizer=keras.optimizers.SGD(lr=0.0001,momentum=0.99),\n",
    " loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])\n",
    "mlstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpXdD2yljd_s",
    "outputId": "46239b43-a401-4f88-aaa3-6e8c355d70f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "65494/65494 [==============================] - 333s 5ms/step - loss: 7.3910 - accuracy: 0.0521 - val_loss: 6.7982 - val_accuracy: 0.0601\n",
      "Epoch 2/20\n",
      "65494/65494 [==============================] - 334s 5ms/step - loss: 6.7760 - accuracy: 0.0560 - val_loss: 6.7952 - val_accuracy: 0.0601\n",
      "Epoch 3/20\n",
      "65494/65494 [==============================] - 340s 5ms/step - loss: 6.7275 - accuracy: 0.0613 - val_loss: 6.7499 - val_accuracy: 0.0728\n",
      "Epoch 4/20\n",
      "65494/65494 [==============================] - 333s 5ms/step - loss: 6.6765 - accuracy: 0.0686 - val_loss: 6.6764 - val_accuracy: 0.0743\n",
      "Epoch 5/20\n",
      "65494/65494 [==============================] - 335s 5ms/step - loss: 6.5771 - accuracy: 0.0750 - val_loss: 6.5759 - val_accuracy: 0.0840\n",
      "Epoch 6/20\n",
      "65494/65494 [==============================] - 347s 5ms/step - loss: 6.4806 - accuracy: 0.0808 - val_loss: 6.5243 - val_accuracy: 0.0859\n",
      "Epoch 7/20\n",
      "65494/65494 [==============================] - 356s 5ms/step - loss: 6.3959 - accuracy: 0.0874 - val_loss: 6.4643 - val_accuracy: 0.0908\n",
      "Epoch 8/20\n",
      "65494/65494 [==============================] - 360s 5ms/step - loss: 6.3062 - accuracy: 0.0908 - val_loss: 6.4254 - val_accuracy: 0.0951\n",
      "Epoch 9/20\n",
      "65494/65494 [==============================] - 347s 5ms/step - loss: 6.2272 - accuracy: 0.0942 - val_loss: 6.3701 - val_accuracy: 0.1063\n",
      "Epoch 10/20\n",
      "65494/65494 [==============================] - 332s 5ms/step - loss: 6.1566 - accuracy: 0.1005 - val_loss: 6.3184 - val_accuracy: 0.1134\n",
      "Epoch 11/20\n",
      "65494/65494 [==============================] - 327s 5ms/step - loss: 6.0487 - accuracy: 0.1081 - val_loss: 6.2871 - val_accuracy: 0.1164\n",
      "Epoch 12/20\n",
      "65494/65494 [==============================] - 311s 5ms/step - loss: 5.9719 - accuracy: 0.1144 - val_loss: 6.2693 - val_accuracy: 0.1206\n",
      "Epoch 13/20\n",
      "65494/65494 [==============================] - 312s 5ms/step - loss: 5.8689 - accuracy: 0.1213 - val_loss: 6.2597 - val_accuracy: 0.1220\n",
      "Epoch 14/20\n",
      "65494/65494 [==============================] - 310s 5ms/step - loss: 5.8006 - accuracy: 0.1284 - val_loss: 6.2110 - val_accuracy: 0.1277\n",
      "Epoch 15/20\n",
      "65494/65494 [==============================] - 306s 5ms/step - loss: 5.7223 - accuracy: 0.1333 - val_loss: 6.2167 - val_accuracy: 0.1294\n",
      "Epoch 16/20\n",
      "65494/65494 [==============================] - 309s 5ms/step - loss: 5.6666 - accuracy: 0.1387 - val_loss: 6.1960 - val_accuracy: 0.1353\n",
      "Epoch 17/20\n",
      "65494/65494 [==============================] - 308s 5ms/step - loss: 5.5824 - accuracy: 0.1422 - val_loss: 6.2006 - val_accuracy: 0.1353\n",
      "Epoch 18/20\n",
      "65494/65494 [==============================] - 309s 5ms/step - loss: 5.5261 - accuracy: 0.1474 - val_loss: 6.2029 - val_accuracy: 0.1309\n",
      "Epoch 19/20\n",
      "65494/65494 [==============================] - 304s 5ms/step - loss: 5.4657 - accuracy: 0.1515 - val_loss: 6.2011 - val_accuracy: 0.1379\n",
      "Epoch 20/20\n",
      "65494/65494 [==============================] - 309s 5ms/step - loss: 5.3760 - accuracy: 0.1572 - val_loss: 6.1983 - val_accuracy: 0.1359\n"
     ]
    }
   ],
   "source": [
    "history2 = mlstm.fit(x,y,batch_size=1,epochs=20,validation_split =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61HqiU3Rji6s",
    "outputId": "cc581016-ca6d-432d-c8a5-67d0c6bf1e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.1597\n",
      "Testing Accuracy:  0.1311\n"
     ]
    }
   ],
   "source": [
    "oss_tr, accuracy_tr = mlstm.evaluate(x, y, verbose=False)\n",
    "print(\"Training Accuracy:  {:.4f}\".format(accuracy_tr)) \n",
    "\n",
    "loss, accuracy = mlstm.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7g91tZByqW0I"
   },
   "outputs": [],
   "source": [
    "#testing function\n",
    "def predict_next_word(model,tokenizer,text,n_words, n_features):\n",
    "    result=''\n",
    "    out_word=[]\n",
    "   \n",
    "    for i in range(n_words):\n",
    "        encoded_data_list = []\n",
    "        for i in range(n_features):\n",
    "            encoded_data=tokenizer.texts_to_sequences([text[i]])[0]           \n",
    "            encoded_data_list.append(encoded_data[0])\n",
    "           \n",
    "        encoded_data_list=np.array(encoded_data_list)\n",
    "        encoded_data_list=encoded_data_list.reshape(1,n_features)\n",
    "        output=np.argmax(model.predict(encoded_data_list))\n",
    "       \n",
    "       \n",
    "        for index,word in tokenizer.word_index.items():\n",
    "            if word==output:\n",
    "                out_word.append(index)\n",
    "                text.append(index)\n",
    "        text = text[1:]\n",
    "    result=' '.join(out_word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FVJsVv-6dKXJ"
   },
   "outputs": [],
   "source": [
    "#testing \n",
    "# predict_next_word(model,tokenizer,['jones', 'friday', 'industrial', 'average', 'stock'],20,num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftfn5UDyoc-g"
   },
   "source": [
    "**Predicting output based on the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_4kfz0d_juaD",
    "outputId": "2f1ead81-1503-4ef4-9239-164329bdf605"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'index futures trading and chief executive officer of the u.s.'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(mlstm,tokenizer,['jones', 'friday', 'industrial', 'average', 'stock'],10,num_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multi_lstm .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
